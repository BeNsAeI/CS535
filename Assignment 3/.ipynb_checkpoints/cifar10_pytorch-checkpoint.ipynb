{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting up...\n",
      "Setting the default tensor type to GPU tensors.\n",
      "Done!\n",
      "Packages imported.\n",
      "Model imported.\n",
      "Functions defined.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "print(\"Starting up...\")\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "print(\"Setting the default tensor type to GPU tensors.\")\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "print(\"Done!\")\n",
    "\n",
    "print(\"Packages imported.\")\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "print(\"Model imported.\")\n",
    "\n",
    "def eval_net(dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    net.eval() # Why would I do this?\n",
    "    criterion = nn.CrossEntropyLoss(size_average=False)\n",
    "    for data in dataloader:\n",
    "        images, labels = data\n",
    "        images, labels = Variable(images).cuda(), Variable(labels).cuda()\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.data).sum()\n",
    "        loss = criterion(outputs, labels)\n",
    "        #total_loss += loss.data[0]\n",
    "        total_loss += loss.data\n",
    "    net.train() # Why would I do this?\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "print(\"Functions defined.\")\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Building model...\n",
      "Start training...\n",
      "    Step:   500 avg_batch_loss: 1.97756\n",
      "    Step:  1000 avg_batch_loss: 1.51816\n",
      "    Step:  1500 avg_batch_loss: 1.28852\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 1 train_loss: 1.16339 train_acc: 0.00000 test_loss: 1.19615 test_acc 0.00000\n",
      "    Step:   500 avg_batch_loss: 1.09552\n",
      "    Step:  1000 avg_batch_loss: 0.98292\n",
      "    Step:  1500 avg_batch_loss: 0.92090\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 2 train_loss: 0.75251 train_acc: 0.00000 test_loss: 0.87653 test_acc 0.00000\n",
      "    Step:   500 avg_batch_loss: 0.76839\n",
      "    Step:  1000 avg_batch_loss: 0.74123\n",
      "    Step:  1500 avg_batch_loss: 0.71739\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 3 train_loss: 0.55679 train_acc: 0.00000 test_loss: 0.77659 test_acc 0.00000\n",
      "    Step:   500 avg_batch_loss: 0.53012\n",
      "    Step:  1000 avg_batch_loss: 0.56339\n",
      "    Step:  1500 avg_batch_loss: 0.57688\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 4 train_loss: 0.36870 train_acc: 0.00000 test_loss: 0.76782 test_acc 0.00000\n",
      "    Step:   500 avg_batch_loss: 0.34930\n",
      "    Step:  1000 avg_batch_loss: 0.40280\n",
      "    Step:  1500 avg_batch_loss: 0.42318\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 5 train_loss: 0.21597 train_acc: 0.00000 test_loss: 0.86092 test_acc 0.00000\n",
      "    Step:   500 avg_batch_loss: 0.21624\n",
      "    Step:  1000 avg_batch_loss: 0.26169\n",
      "    Step:  1500 avg_batch_loss: 0.30559\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 6 train_loss: 0.19817 train_acc: 0.00000 test_loss: 1.04254 test_acc 0.00000\n",
      "    Step:   500 avg_batch_loss: 0.17237\n",
      "    Step:  1000 avg_batch_loss: 0.20229\n",
      "    Step:  1500 avg_batch_loss: 0.23849\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 7 train_loss: 0.19055 train_acc: 0.00000 test_loss: 1.29123 test_acc 0.00000\n",
      "    Step:   500 avg_batch_loss: 0.12400\n",
      "    Step:  1000 avg_batch_loss: 0.16027\n",
      "    Step:  1500 avg_batch_loss: 0.18181\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 8 train_loss: 0.11747 train_acc: 0.00000 test_loss: 1.12645 test_acc 0.00000\n",
      "    Step:   500 avg_batch_loss: 0.10927\n",
      "    Step:  1000 avg_batch_loss: 0.14120\n",
      "    Step:  1500 avg_batch_loss: 0.15092\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 9 train_loss: 0.15454 train_acc: 0.00000 test_loss: 1.37388 test_acc 0.00000\n",
      "    Step:   500 avg_batch_loss: 0.09231\n",
      "    Step:  1000 avg_batch_loss: 0.12164\n",
      "    Step:  1500 avg_batch_loss: 0.14250\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 10 train_loss: 0.08407 train_acc: 0.00000 test_loss: 1.40820 test_acc 0.00000\n",
      "Finished Training\n",
      "Saving model...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    BATCH_SIZE = 32 #mini_batch size\n",
    "    MAX_EPOCH = 10 #maximum epoch to train\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) #torchvision.transforms.Normalize(mean, std)\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                             shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    print('Building model...')\n",
    "    net = Net().cuda()\n",
    "    net.train() # Why would I do this?\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "    print('Start training...')\n",
    "    for epoch in range(MAX_EPOCH):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "\n",
    "            # wrap them in Variable\n",
    "            inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print statistics\n",
    "            #running_loss += loss.data[0]\n",
    "            running_loss += loss.data\n",
    "            if i % 500 == 499:    # print every 2000 mini-batches\n",
    "                print('    Step: %5d avg_batch_loss: %.5f' %\n",
    "                      (i + 1, running_loss / 500))\n",
    "                running_loss = 0.0\n",
    "        print('    Finish training this EPOCH, start evaluating...')\n",
    "        train_loss, train_acc = eval_net(trainloader)\n",
    "        test_loss, test_acc = eval_net(testloader)\n",
    "        print('EPOCH: %d train_loss: %.5f train_acc: %.5f test_loss: %.5f test_acc %.5f' %\n",
    "              (epoch+1, train_loss, train_acc, test_loss, test_acc))\n",
    "    print('Finished Training')\n",
    "    print('Saving model...')\n",
    "    torch.save(net.state_dict(), 'mytraining.pth')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
